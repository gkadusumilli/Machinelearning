{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Restoration using the SRCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUufi2QQ9w8W",
        "colab_type": "text"
      },
      "source": [
        "# Image Restoration using Convolutional Nueral Network \n",
        "\n",
        "                                     -Gopalakrishna Adusumilli\n",
        "\n",
        "**Learning outcomes**\n",
        "\n",
        "\n",
        "*   Super Resolution\n",
        "*   SRCNN Network\n",
        "*   Evaluating the performance of the SRCNN, using popular image quality metrics: **Peak Signal to Noise  Ratio(PSNR)**,  **Mean Squared Error(MSE)** , **the structural similarity(SSIM) index.**\n",
        "*  Processing of Images using Open CV.\n",
        "*   Conversion between the RGB,BGR,YCrCb color spaces.\n",
        "*   Building deep neural networks in keras.\n",
        "*   Deploy and evaluate the SRCNN network.\n",
        "\n",
        "\n",
        "##What is Super Resolution ?\n",
        "Super resolution is the process of upscaling and or improving the details within an image. Often a low resolution image is taken as an input and the same image is upscaled to a higher resolution, which is the output. The details in the high resolution output are filled in where the details are essentially unknown.\n",
        "\n",
        "\n",
        "##SRCNN Network\n",
        "\n",
        "SRCNN is a deep convolutional neural network that learns the end-to-end mapping of low resolution to high resolution images. Results, improving the image quality of low resolution images.\n",
        "![alt text](https://miro.medium.com/max/1050/1*mZJO-i6ImYyXHorv4H1q_Q.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnuRnfCBnOtQ",
        "colab_type": "text"
      },
      "source": [
        "## 1. Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlLNPXvY9p0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check package versions\n",
        "import sys\n",
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import skimage\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.optimizers import adam\n",
        "from skimage.measure import compare_ssim as ssim\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "#to display pyplot figures in the notebook\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp2iCzLTpDlM",
        "colab_type": "text"
      },
      "source": [
        "##2. Defining Image Quality Metrics\n",
        "\n",
        "**MSE**: The MSE represents the cumulative squared error between the compressed and the original image\n",
        "\n",
        "**PSNR**: The PSNR block computes the peak signal-to-noise ratio, in decibels, between two images. This ratio is often used as a quality measurement between the original and a compressed image.\n",
        "![alt text](https://qph.fs.quoracdn.net/main-qimg-bb07713cb739bfb11abb4f7eb6da3acd.webp)\n",
        "\n",
        "where M & N in the MSE formula are the number of rows and columns in our image matrix.\n",
        "\n",
        "**SSIM(Structural Similarity Index)**: SSIM actually measures the perceptual difference between two similar images.\n",
        "SSIM is based on visible struuctures of the image.\n",
        "\n",
        "SSIM index will be imported directly from the scikit-image library.\n",
        "\n",
        "\n",
        "**Objective:**\n",
        "1. Defining own functions for the PSNR and MSE\n",
        "\n",
        "2. Wrapping all three of these metrics into a single function that we can call later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IKb0czBs4kF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a function for peak signal-to-noise ratio (PSNR)\n",
        "\n",
        "def psnr(target,ref):\n",
        "  #assume RGB image\n",
        "  target_data=target.astype(float)\n",
        "  ref_data=ref.astype(float)\n",
        "  \n",
        "  diff=ref_data-target_data\n",
        "  diff=diff.flatten('c')\n",
        "  \n",
        "  rmse=math.sqrt(np.mean(diff**2.))\n",
        "  \n",
        "  return 20*math.log10(255. /rmse)\n",
        "\n",
        "\n",
        "#define function for mean squared error(MSE)\n",
        "\n",
        "def mse(target,ref):\n",
        "  #the MSE between the two images is the sum of the squared diffrence between two images\n",
        "  err=np.sum((target.astype('float')-ref.astype('float'))**2)\n",
        "  err /=float(target.shape[0]*target.shape[1])\n",
        "  \n",
        "  return err\n",
        "\n",
        "#define function that combines all three image quality metrics\n",
        "def compare_images(target,ref):\n",
        "  scores=[]\n",
        "  scores.append(psnr(target,ref))\n",
        "  scores.append(mse(target,ref))\n",
        "  scores.append(ssim(target,ref,multichannel=True))\n",
        "  \n",
        "  return scores\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gtog-AVVat7",
        "colab_type": "text"
      },
      "source": [
        "## 3. Preparing Images\n",
        "\n",
        "**Dataset**: [Dataset](http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html). the .ZIP file contain set5 and set14 datasets into a new folder **\"Source\"**\n",
        "\n",
        "**Objective**\n",
        "1. We need to produce low-resolution versions of these images. we can accomplish this by resizing the images,both downwards and upwards,using openCV.\n",
        "\n",
        "**Approach**\n",
        "Using Interpolation methods that can be used to resize images, however in this project we will use **Bilinear Transformation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoMZdwziWlPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare degraded images by introducing quality distortions via resizing\n",
        "\n",
        "def prepare_images(path,factor):\n",
        "  #loop through the files in the directory\n",
        "  for file in os.listdir(path):\n",
        "    #open the file\n",
        "    img=cv2.imread(path+'/'+file)\n",
        "    \n",
        "    #find old and new image dimensions \n",
        "    h,w,_=img.shape\n",
        "    new_height=h/ factor\n",
        "    new_width=w / factor\n",
        "    \n",
        "    #resize the image -down\n",
        "    img=cv2.resize(img,(w,h),interpolation=cv2.INTER_LINEAR)\n",
        "    \n",
        "    #save the image\n",
        "    print('saving {}'.format(file))\n",
        "    cv2.imwrite('images/{}'.format(file),img)\n",
        "prepare_images('source/'2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-T76zBbcrMj",
        "colab_type": "text"
      },
      "source": [
        "## 3. Testing Low-Resolution Images\n",
        "\n",
        "**Objective**\n",
        "Calculating Image Metrics on our refereced images and that the degraded images that we just prepared\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt1KyV79wIsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test the generated images using the image quality metrics\n",
        "for file in os.listdir('images/'):\n",
        "  \n",
        "  #open target and reference images\n",
        "  target=cv2.imread('images/{}'.format(file))\n",
        "  \n",
        "  ref=cv2.imread('source/{}'.format(file))\n",
        "  \n",
        "  #calculate score\n",
        "  scores=compare_images(target,ref)\n",
        "  \n",
        "  #print all three scores with new line charactes (\\n)\n",
        "  print('{}\\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(file, scores[0], scores[1], scores[2]))\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPGFYb6vxLrH",
        "colab_type": "text"
      },
      "source": [
        "## 4. Building the SRCNN Model\n",
        "\n",
        "**Objective:**\n",
        "  Building the SRCNN. iN KERAS, it is simple as adding layers one after the other. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGlxBKSUwzA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the SRCNN model\n",
        "\n",
        "def model():\n",
        "  #define model type\n",
        "  SRCNN=Sequential()\n",
        "  \n",
        "  #add model layers\n",
        "  \n",
        "  SRCNN.add(Conv2D(filters=128,kernel_size=(9,9),kernel_initializer='glorot_uniform'\n",
        "                  activation='relu',padding='valid',use_bias=True,input_shape=(None,None,1)))\n",
        "  \n",
        "  SRCNN.add(Conv2D(filters=64,kernel_size=(9,9),kernel_initializer='glorot_uniform'\n",
        "                  activation='relu',padding='valid',use_bias=True))\n",
        "  \n",
        "  SRCNN.add(Conv2D(filters=1,kernel_size=(9,9),kernel_initializer='glorot_uniform'\n",
        "                  activation='relu',padding='valid'))\n",
        "  \n",
        "  \n",
        "  #define optimizer\n",
        "  \n",
        "  adam=Adam(lr=0.0003)\n",
        "  \n",
        "  #compile model\n",
        "  \n",
        "  SRCNN.compile(optimizer=adam,loss='mean_squared_error',metrics=['mean_squared_error'])\n",
        "  \n",
        "  return SRCNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEpnbAB8zcpv",
        "colab_type": "text"
      },
      "source": [
        "## 5. Deploying the SRCNN\n",
        "\n",
        "**Objectives**\n",
        "1. Preprocessing the Images extensively before using them as inputs to the network. This processing will include cropping and color space conversions.\n",
        "\n",
        "2. Loading pre-trained model(to save time to train a deep neural network) these weights can be found at the following [Github](https://github.com/MarkPrecursor/SRCNN-keras)\n",
        "\n",
        "3. Performing single-image super resolution on all our input images. Furhermore, after processing, we can calculate the PSNR,MSE, and SSIM on the images that we produce.\n",
        "\n",
        "4. Creating subplots to convineantly display the orginal, low resolution, and high resolution images side by side"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPFfXDb91mAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define necessary image processing functions\n",
        "\n",
        "def modcrop(img, scale):\n",
        "    tmpsz = img.shape\n",
        "    sz = tmpsz[0:2]\n",
        "    sz = sz - np.mod(sz, scale)\n",
        "    img = img[0:sz[0], 1:sz[1]]\n",
        "    return img\n",
        "\n",
        "\n",
        "def shave(image, border):\n",
        "    img = image[border: -border, border: -border]\n",
        "    return img\n",
        "# define main prediction function\n",
        "\n",
        "def predict(image_path):\n",
        "    \n",
        "    # load the srcnn model with weights\n",
        "    srcnn = model()\n",
        "    srcnn.load_weights('3051crop_weight_200.h5')\n",
        "    \n",
        "    # load the degraded and reference images\n",
        "    path, file = os.path.split(image_path)\n",
        "    degraded = cv2.imread(image_path)\n",
        "    ref = cv2.imread('source/{}'.format(file))\n",
        "    \n",
        "    # preprocess the image with modcrop\n",
        "    ref = modcrop(ref, 3)\n",
        "    degraded = modcrop(degraded, 3)\n",
        "    \n",
        "    # convert the image to YCrCb - (srcnn trained on Y channel)\n",
        "    temp = cv2.cvtColor(degraded, cv2.COLOR_BGR2YCrCb)\n",
        "    \n",
        "    # create image slice and normalize  \n",
        "    Y = numpy.zeros((1, temp.shape[0], temp.shape[1], 1), dtype=float)\n",
        "    Y[0, :, :, 0] = temp[:, :, 0].astype(float) / 255\n",
        "    \n",
        "    # perform super-resolution with srcnn\n",
        "    pre = srcnn.predict(Y, batch_size=1)\n",
        "    \n",
        "    # post-process output\n",
        "    pre *= 255\n",
        "    pre[pre[:] > 255] = 255\n",
        "    pre[pre[:] < 0] = 0\n",
        "    pre = pre.astype(np.uint8)\n",
        "    \n",
        "    # copy Y channel back to image and convert to BGR\n",
        "    temp = shave(temp, 6)\n",
        "    temp[:, :, 0] = pre[0, :, :, 0]\n",
        "    output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2BGR)\n",
        "    \n",
        "    # remove border from reference and degraged image\n",
        "    ref = shave(ref.astype(np.uint8), 6)\n",
        "    degraded = shave(degraded.astype(np.uint8), 6)\n",
        "    \n",
        "    # image quality calculations\n",
        "    scores = []\n",
        "    scores.append(compare_images(degraded, ref))\n",
        "    scores.append(compare_images(output, ref))\n",
        "    \n",
        "    # return images and scores\n",
        "    return ref, degraded, output, scores\n",
        "ref, degraded, output, scores = predict('images/flowers.bmp')\n",
        "\n",
        "# print all scores for all images\n",
        "print('Degraded Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(scores[0][0], scores[0][1], scores[0][2]))\n",
        "print('Reconstructed Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(scores[1][0], scores[1][1], scores[1][2]))\n",
        "\n",
        "\n",
        "# display images as subplots\n",
        "fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
        "axs[0].imshow(cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))\n",
        "axs[0].set_title('Original')\n",
        "axs[1].imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
        "axs[1].set_title('Degraded')\n",
        "axs[2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
        "axs[2].set_title('SRCNN')\n",
        "\n",
        "# remove the x and y ticks\n",
        "for ax in axs:\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXLDCCo11te9",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/1050/1*j9a0kGhWcG8lEDLf5eqcfg.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0dULpON1yrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in os.listdir('images'):\n",
        "    \n",
        "    # perform super-resolution\n",
        "    ref, degraded, output, scores = predict('images/{}'.format(file))\n",
        "    \n",
        "    # display images as subplots\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
        "    axs[0].imshow(cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))\n",
        "    axs[0].set_title('Original')\n",
        "    axs[1].imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
        "    axs[1].set_title('Degraded')\n",
        "    axs[1].set(xlabel = 'PSNR: {}\\nMSE: {} \\nSSIM: {}'.format(scores[0][0], scores[0][1], scores[0][2]))\n",
        "    axs[2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
        "    axs[2].set_title('SRCNN')\n",
        "    axs[2].set(xlabel = 'PSNR: {} \\nMSE: {} \\nSSIM: {}'.format(scores[1][0], scores[1][1], scores[1][2]))\n",
        "\n",
        "    # remove the x and y ticks\n",
        "    for ax in axs:\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "      \n",
        "    print('Saving {}'.format(file))\n",
        "    fig.savefig('output/{}.png'.format(os.path.splitext(file)[0])) \n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqJf97R_15Xm",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/1050/1*8lpeTi2p_F7AhE2o_7tJ9Q.png)"
      ]
    }
  ]
}